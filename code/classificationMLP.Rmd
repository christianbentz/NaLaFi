---
title: "Classification with Multilayer Perceptron (MLP)"
author: "Chris Bentz"
date: "18/01/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Packages
If the libraries are not installed yet, you need to install them using, for example, the command: install.packages("ggplot2"). For the Hrate package this is different, since it comes from github. The devtools library needs to be installed, and then the install_github() function is used.
```{r, message = F}
# install the latest version of neuralnet with bug fixes: devtools::install_github("bips-hb/neuralnet")
library(neuralnet)
library(caret)
```

# Load Data
Load data table with values per text file. 
```{r}
# load estimations from stringBase corpus
estimations.df <- read.csv("~/Github/NaLaFi/results/features.csv")
#head(features.csv)
```

Exclude subcorpora (if needed).
```{r}
#selected <- c("shuffled", "random")
#estimations.df <- estimations.df[!(estimations.df$subcorpus %in% selected), ]
```

Split into separate files by length of chunks in characters.
```{r}
# choose number of characters
num.char = 100
# subset data frame
estimations.df <- estimations.df[estimations.df$num.char == num.char, ]
```

Select relevant columns of the data frame, i.e. the measures to be included in classification and the ''corpus'' or ''subcorpus'' column.
```{r}
estimations.subset <- estimations.df[c("corpus",
                                       "huni.chars", 
                                       "hrate.chars", 
                                       "ttr.chars", 
                                       "rm.chars"
                                       )]
```

Remove NAs (whole row)
```{r}
estimations.subset <- na.omit(estimations.subset)
```

# Center and scale the data
```{r}
estimations.scaled <- cbind(estimations.subset[1], scale(estimations.subset[2:ncol(estimations.subset)]))
```

# Convert to Boolean
The MLP classisfiers in the neuralnet library require Boolean values for the response.
```{r}
#levels(estimations.scaled$corpus) <- c(FALSE,TRUE)
#df$y <- as.logical(df$y)
```

# Create Training and Test Sets
```{r}
# Generating seed
set.seed(1234)
# Randomly generating our training and test samples with a respective ratio of 2/3 and 1/3
datasample <- sample(2, nrow(estimations.scaled), replace = TRUE, prob = c(0.67, 0.33))
# Generate training set
train <- estimations.scaled[datasample == 1, 1:ncol(estimations.scaled)]
# Generate test set 
test <- estimations.scaled[datasample == 2, 1:ncol(estimations.scaled)]
```

# Implement MLP classifier
This is based on code given at http://uc-r.github.io/ann_classification (last accessed 18.01.2023)
```{r}
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus == "writing" ~ ., 
                     data = train,
                     hidden = c(3, 2),
                     threshold = 0.1, # defaults to 0.01
                     rep = 10, # number of reps in which new initial values are used, 
                     # (essentially the same as a for loop)
                     stepmax = 100000, # defaults to 100K
                     linear.output = FALSE,
                     algorithm = "rprop+", # defaults to "rprop+",
                     # i.e. resilient backpropagation
                     err.fct = 'ce', 
                     act.fct = 'logistic', 
                     likelihood = TRUE,
                     lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
```

# Visualize the NN
Visualize the nn with the best weights after training.
```{r}
plot(classifier.mlp, rep = 'best')
```

# Predict with NN
Predict response values based on the "best" repetition (epoche), i.e. the one with the lowest error in terms of cross entropy.
```{r}
mlp.predictions <- predict(classifier.mlp, test, rep = 4, all.units = FALSE)
# assign a label according to the rule that the label is "writing" if the prediction probability is >0.5, else assign "non-writing". 
mlp.predictions.rd <- ifelse(mlp.predictions > 0.5, "writing", "non-writing")
head(mlp.predictions.rd, 10)
#table(test$corpus == "non-writing", predictions[, 1] > 0.5)
```

# Model Evaluation
```{r}
# creating a dataframe from known (true) test labels
test.labels <- data.frame(test$corpus)
# combining predicted and known classes
class.comparison <- data.frame(mlp.predictions.rd, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, 
                      reference = class.comparison$observed)
print(cm)
# get precision, recall, and f1 from the output list of confusionMatrix()
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
  
# prepare data frame with results
mlp.results <- data.frame(precision, recall, f1, row.names = NULL)
mlp.results.rounded <- round(mlp.results, 2)
print(mlp.results.rounded)
```

Write to file.
```{r}
write.csv(mlp.results.rounded, file = paste("~/Github/NaLaFi/results/MLP/results_MLP_", 
                                      paste(num.char, ".csv", sep = ""), 
                                   sep = ""), row.names = F)
```
