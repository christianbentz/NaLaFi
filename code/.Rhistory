knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(caret)
# load estimations from stringBase corpus
estimations.df <- read.csv("~/Github/NaLaFi/results/features.csv")
num.char = 100
# subset data frame
estimations.df <- estimations.df[estimations.df$num.char == num.char, ]
estimations.subset <- estimations.df[c("corpus",
"huni.chars",
"hrate.chars",
"ttr.chars",
"rm.chars"
)]
estimations.subset <- na.omit(estimations.subset)
estimations.scaled <- cbind(estimations.subset[1], scale(estimations.subset[2:ncol(estimations.subset)]))
levels(estimations.scaled$corpus) <- c(FALSE,TRUE)
set.seed(1234)
# Randomly generating our training and test samples with a respective ratio of 2/3 and 1/3
datasample <- sample(2, nrow(estimations.scaled), replace = TRUE, prob = c(0.67, 0.33))
# Generate training set
train <- estimations.scaled[datasample == 1, 1:ncol(estimations.scaled)]
# Generate test set
test <- estimations.scaled[datasample == 2, 1:ncol(estimations.scaled)]
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10,
linear.output = FALSE,
err.fct = 'ce',
likelihood = TRUE)
end_time <- Sys.time()
end_time - start_time
plot(classifier.mlp, rep = 'best')
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10,
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE)
end_time <- Sys.time()
end_time - start_time
plot(classifier.mlp, rep = 'best')
classifier.mlp
predict(classifier.mlp, test, rep = 'best', all.units = FALSE)
predict(classifier.mlp, test, rep = 1, all.units = FALSE)
predict(classifier.mlp, test, rep = 10, all.units = FALSE)
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10,
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full')
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 1, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'minimal')
end_time <- Sys.time()
end_time - start_time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 1, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full')
end_time <- Sys.time()
end_time - start_time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 1, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 10000)
end_time <- Sys.time()
end_time - start_time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 1, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 10000)
end_time <- Sys.time()
end_time - start_time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
end_time <- Sys.time()
end_time - start_time
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
classifier.mlp
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'full',
lifesign.step = 1000)
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
classifier.mlp$net.result
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'relu',
likelihood = TRUE,
lifesign = 'minimal',
lifesign.step = 1000)
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 10000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal',
lifesign.step = 1000)
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal',
lifesign.step = 1000)
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
plot(classifier.mlp, rep = 1)
plot(classifier.mlp, rep = 'best')
plot.nn(classifier.mlp, rep = 'best')
plot(classifier.mlp, rep = 'best')
plot(classifier.mlp, rep = 5)
plot(classifier.mlp, rep = 'best')
?neuralnet()
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "backprop", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "backprop", # defaults to "rprop+",
# i.e. resilient backpropagation
learningrate = 0.3,
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 1000000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "backprop", # defaults to "rprop+",
# i.e. resilient backpropagation
learningrate = 0.3,
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
hidden = 3,
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus ~ .,
data = train,
hidden = 3,
threshold = 0.1, # defaults to 0.01
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
?compute()
predictions <- predict(classifier.mlp, test, rep = 1, all.units = FALSE)
predictions <- predict(classifier.mlp, test, rep = 1, all.units = FALSE)
predictions
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus == "non-writing" ~ .,
data = train,
hidden = 3,
threshold = 0.1, # defaults to 0.01
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus == "non-writing" ~ .,
data = train,
hidden = 3,
threshold = 0.1, # defaults to 0.01
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
estimations.df <- read.csv("~/Github/NaLaFi/results/features.csv")
num.char = 100
# subset data frame
estimations.df <- estimations.df[estimations.df$num.char == num.char, ]
estimations.subset <- estimations.df[c("corpus",
"huni.chars",
"hrate.chars",
"ttr.chars",
"rm.chars"
)]
estimations.subset <- na.omit(estimations.subset)
estimations.scaled <- cbind(estimations.subset[1], scale(estimations.subset[2:ncol(estimations.subset)]))
set.seed(1234)
# Randomly generating our training and test samples with a respective ratio of 2/3 and 1/3
datasample <- sample(2, nrow(estimations.scaled), replace = TRUE, prob = c(0.67, 0.33))
# Generate training set
train <- estimations.scaled[datasample == 1, 1:ncol(estimations.scaled)]
# Generate test set
test <- estimations.scaled[datasample == 2, 1:ncol(estimations.scaled)]
head(train)
head(test)
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus == "non-writing" ~ .,
data = train,
hidden = 3,
threshold = 0.1, # defaults to 0.01
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
predictions <- predict(classifier.mlp, test, rep = 1, all.units = FALSE)
head(predictions)
table(test$corpus == "non-writing", predictions[, 1] > 0.5)
cm(test$corpus == "non-writing", predictions[, 1] > 0.5)
head(predictions[,1])
test.labels <- data.frame(test$corpus)
mlp.predictions <- predict(classifier.mlp, test, rep = 1, all.units = FALSE)
head(mlp.predictions)
set.seed(123)
# start time
start_time <- Sys.time()
classifier.mlp <- neuralnet(corpus == "writing" ~ .,
data = train,
hidden = 3,
threshold = 0.1, # defaults to 0.01
rep = 10, # number of reps in which new initial values are used,
# (essentially the same as a for loop)
stepmax = 100000, # defaults to 100K
linear.output = FALSE,
algorithm = "rprop+", # defaults to "rprop+",
# i.e. resilient backpropagation
err.fct = 'ce',
act.fct = 'logistic',
likelihood = TRUE,
lifesign = 'minimal')
#classifier.mlp
end_time <- Sys.time()
end_time - start_time
# results matrix (each column represents one repetition)
classifier.mlp$result.matrix
plot(classifier.mlp, rep = 'best')
mlp.predictions <- predict(classifier.mlp, test, rep = 4, all.units = FALSE)
# assign a label according to the rule that the label is "writing" if the prediction probability is >0.5, else assign "non-writing".
mlp.predictions.rd <- ifelse(mlp.predictions > 0.5, "writing", "non-writing")
head(mlp.prediction.rd, 10)
mlp.predictions <- predict(classifier.mlp, test, rep = 4, all.units = FALSE)
# assign a label according to the rule that the label is "writing" if the prediction probability is >0.5, else assign "non-writing".
mlp.predictions.rd <- ifelse(mlp.predictions > 0.5, "writing", "non-writing")
head(mlp.predictions.rd, 10)
test.labels <- data.frame(test$corpus)
# combining predicted and known classes
class.comparison <- data.frame(mlp.predictions, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
test.labels <- data.frame(test$corpus)
# combining predicted and known classes
class.comparison <- data.frame(mlp.predictions.rd, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed)
print(cm)
