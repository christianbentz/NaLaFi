file.list.teddi <- sample(file.list.teddi, 1000)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
file.list.combined
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
file.list.teddi <- sample(file.list.teddi, 10)
file.list.teddi
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
file.list.teddi <- sample(file.list.teddi, 100)
file.list.teddi
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
# (using all 23K files would yield an extremely unbalanced sample)
file.list.teddi <- sample(file.list.teddi, 100)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
file.list.combined
file = "/home/chris/Data/TeDDi_dumps/Teddi_unifiedformat/ind_nfi_337.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
head(textfile)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
head(textfile)
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
# (using all 23K files would yield an extremely unbalanced sample)
file.list.teddi <- sample(file.list.teddi, 10)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
textfile
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
library(stringr)
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here.
chars <- unlist(strsplit(textfile, ""))
chars <- chars[1:n] # use only maximally n units
chars <- chars[!is.na(chars)] # remove NAs for vectors which are already shorter than n
chars
filename <- basename(file)
filename
filename
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename)
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename)
} else {
new.filename <- paste('writing_teddi_', filename)
}
new.filename
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename, sep = "")
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename, sep = "")
} else {
new.filename <- paste('writing_teddi_', filename, sep = "")
}
new.filename
file = "/home/chris/Github/NaLaFi/data/writing/udhr/udhr_arb_0001.txt"
filename <- basename(file)
# create new file name
# note: this is dependent on the exact file extensions (!)
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename, sep = "")
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename, sep = "")
} else {
new.filename <- paste('writing_teddi_', filename, sep = "")
}
new.filename
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
chars <- chars[1:n] # use only maximally n units
chars <- chars[!is.na(chars)] # remove NAs for vectors which are already shorter than n
# chars <- chars[chars != " "] # remove white spaces from character vector
chars
char.num <- 10
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
chars <- chars[1:char.num] # use only maximally n units
chars <- chars[!is.na(chars)] # remove NAs for vectors which are already shorter than n
# chars <- chars[chars != " "] # remove white spaces from character vector
# prepare writing to file
# get original filename
filename <- basename(file)
# create new file name
# note: this is dependent on the exact file extensions (!)
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename, sep = "")
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename, sep = "")
} else {
new.filename <- paste('writing_teddi_', filename, sep = "")
}
chars
paste("~/Github/NaLaFi/samples/", paste(num.chars, "chars", sep = ""), sep = "")
paste("~/Github/NaLaFi/samples/", paste(char.num, "chars", sep = ""), sep = "")
c("~/Github/NaLaFi/samples/", new.filename)
paste("~/Github/NaLaFi/samples/", new.filename)
paste("~/Github/NaLaFi/samples/", new.filename, sep = "")
paste("~/Github/NaLaFi/samples/", paste(num.chars, new.filename, sep = "_"), sep = "")
paste("~/Github/NaLaFi/samples/", paste(char.num, new.filename, sep = "_"), sep = "")
chars
write.table(chars, paste("~/Github/NaLaFi/samples/", paste(char.num, new.filename, sep = "_"), sep = ""),
sep = "")
write.table(chars, paste("~/Github/NaLaFi/samples/", paste(char.num, new.filename, sep = "_"), sep = ""),
sep = "")
writeLines(chars, paste("~/Github/NaLaFi/samples/", paste(char.num, new.filename, sep = "_"), sep = ""))
writeLines(chars, paste("~/Github/NaLaFi/samples/", paste(char.num, new.filename, sep = "_"), sep = ""), sep = "")
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
# (using all 23K files would yield an extremely unbalanced sample)
file.list.teddi <- sample(file.list.teddi, 10)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
char.num <- 10
# start time
start_time <- Sys.time()
for (file in file.list.combined){
try({ # if the processing fails for a certain file, there will be no output for this file,
# but the try() function allows the loop to keep running
# basic processing
# loading textfile
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
chars <- chars[1:char.num] # use only maximally n units
chars <- chars[!is.na(chars)] # remove NAs for vectors which are already shorter than n
# chars <- chars[chars != " "] # remove white spaces from character vector
# prepare writing to file
# get original filename
filename <- basename(file)
# create new file name
# note: this is dependent on the exact file extensions (!)
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename, sep = "")
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename, sep = "")
} else {
new.filename <- paste('writing_teddi_', filename, sep = "")
}
# write to file
writeLines(chars, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
sep = "")
})
}
end_time <- Sys.time()
end_time - start_time
file
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
chars
?strsplit()
substring(textfile,                     # Apply substring function
seq(1, nchar(textfile), char.num),
seq(char.num, nchar(my_string), char.num))
substring(textfile,                     # Apply substring function
seq(1, nchar(textfile), char.num),
seq(char.num, nchar(textfile), char.num))
char.num
seq(1, nchar(textfile), char.num)
nchar(textfile)
textfile
chars
substring(chars,                     # Apply substring function
seq(1, nchar(chars), char.num),
seq(char.num, nchar(chars), char.num))
nchar(chars)
typeof(chars
)
chars[1:10]
head(textfile)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "" , skip = 0)
head(textfile)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
head(chars)
typeof(chars)
split(chars, ceiling(seq_along(chars)/10))
chunks <- split(chars, ceiling(seq_along(chars)/10))
head(chunks)
typeof(chunks)
lapply(chunks, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append=TRUE, ncolumns=1000)
?write()
lapply(chunks, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append=TRUE, sep = "")
lapply(chunks, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append=TRUE, sep = "")
lapply(chunks, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append = TRUE, ncolumns = char.num, sep = "")
lapply(chunks, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append = TRUE, ncolumns = char.num, sep = "")
file = "/home/chris/Github/NaLaFi/data/non-writing/animal/animal_cat_0001.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
file = "/home/chris/Github/NaLaFi/data/non-writing/animal/animal_cad_0001.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into chunks of size char.num (i.e. 10, 100, 1000)
chunks <- split(chars, ceiling(seq_along(chars)/char.num))
chunks
?Filter(9)
Filter(function(x) length(x) = char.num, chunks)
chunks
Filter(function(x) length(x) == 10, chunks)
chunks
Filter(function(x) length(x) == char.num, chunks)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
# remove chunks from list which are shorter than char.num (the last chunk likely is)
chunks.list <- Filter(function(x) length(x) == char.num, chunks)
# prepare writing to file
# get original filename
filename <- basename(file)
# create new file name
# note: this is dependent on the exact file extensions (!)
if (grepl('non-writing', file)){
new.filename <- paste('non-writing_', filename, sep = "")
} else if (grepl('writing', file)){
new.filename <- paste('writing_', filename, sep = "")
} else {
new.filename <- paste('writing_teddi_', filename, sep = "")
}
# write to file
lapply(chunks.list, write, paste("~/Github/NaLaFi/samples/",
paste(char.num, new.filename, sep = "_"), sep = ""),
append = TRUE, ncolumns = char.num, sep = "")
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
# remove chunks from list which are shorter than char.num (the last chunk likely is)
chunks.list <- Filter(function(x) length(x) == char.num, chunks.list)
head(chunks.list)
file
file = "/home/chris/Github/NaLaFi/data/non-writing/natural/natural_dna_0001.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
# remove chunks from list which are shorter than char.num (the last chunk likely is)
chunks.list <- Filter(function(x) length(x) == char.num, chunks.list)
head(chunks.list)
chunks.list[1:10]
chunks.list
length(chunks.list)
char.num
char.num <- 100
file = "/home/chris/Github/NaLaFi/data/non-writing/animal/animal_cad_0001.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
# remove chunks from list which are shorter than char.num (the last chunk likely is)
chunks.list <- Filter(function(x) length(x) == char.num, chunks.list)
# limit number of chunks to maximally 100 (for some text files are much larger than others)
chunks.list <- chunks.list[1:100]
chunks.list
length(chunks.list)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
chunks.list
chunks.list <- Filter(function(x) length(x) == char.num, chunks.list)
chunks.list
length(chunks.list)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
# remove the header lines beginning with '#'
textfile <- textfile[!grepl('^#.*$', textfile)]
# remove annotations marked by '<>'
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# Split into individual characters/signs
# remove tabs and parentheses, as well as star signs `*' and plus signs `+´
# note that this might have to be tuned according to the text files included
textfile <- str_replace_all(textfile, c("\\\t" = "", "\\(" = "", "\\)" = "",
"\\]" = "", "\\[" = "",  "\\}" = "",
"\\{" = "", "\\*" = "", "\\+" = ""))
# split the textfile into individual utf-8 characters. Note that white spaces are
# counted as utf-8 characters here and not removed (to remove them uncomment line below).
chars <- unlist(strsplit(textfile, ""))
# chars <- chars[chars != " "] # remove white spaces from character vector
# split into list of chunks of size char.num (i.e. 10, 100, 1000)
chunks.list <- split(chars, ceiling(seq_along(chars)/char.num))
# remove chunks from list which are shorter than char.num (the last chunk likely is)
chunks.list <- Filter(function(x) length(x) == char.num, chunks.list)
# use break statement to exclude empty chunks list
if (length(chunks.list) == 0) {
break
}
