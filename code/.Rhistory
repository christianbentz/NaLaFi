library(ggrepel)
library(plyr)
library(ggExtra)
library(ggpubr)
huni.hrate.chars.plot <- ggplot(estimations1000.df,
aes(x = huni.chars, y = ttr.chars,
colour = subcorpus)) +
geom_point(alpha = 0.5, size  = 1) +
labs(x = "Unigram entropy for characters", y = "TTR for characters") +
facet_wrap(~ subcorpus, ncol = 2) +
theme(legend.position = "none")
huni.hrate.chars.plot
huni.hrate.chars.plot <- ggplot(estimations1000.df,
aes(x = huni.chars, y = ttr.chars,
colour = subcorpus)) +
geom_point(alpha = 0.5, size  = 1) +
labs(x = "Unigram entropy for characters", y = "TTR for characters") +
facet_wrap(~ subcorpus, ncol = 3) +
theme(legend.position = "none")
#huni.hrate.chars.plot <- ggMarginal(huni.hrate.chars.plot, groupFill = T, type = "histogram", colour = "white")
huni.hrate.chars.plot
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(ggplot2)
library(plyr)
file.list <- list.files(path = "~/Github/NaLaFi/data/",
recursive = T, full.names = T)
#print(file.list)
length(file.list)
knitr::opts_chunk$set(echo = TRUE)
library(stringi)
library(gsubfn)
file.list <- list.files(path = "~/Github/NaLaFi/data/writing/udhr/",
recursive = T, full.names = T)
#print(file.list)
length(file.list)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(ggplot2)
library(ggrepel)
library(plyr)
library(entropy)
library(ggExtra)
library(gsubfn)
#library(devtools)
#install_github("dimalik/Hrate")
library(Hrate)
file.list <- list.files(path = "~/Github/NaLaFi/data/",
recursive = T, full.names = T)
head(file.list)
length(file.list)
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
typeof(file.list.teddi)
file.list.combined <- c(file.list, file.list.teddi)
file.list.combined
?teddi
?sample()
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
file.list.teddi <- sample(file.list.teddi, 1000)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
file="/home/chris/Data/TeDDi_dumps/Teddi_unifiedformat/apu_nfi_1.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 7)
textfile
head(textfile)
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
textfile <- gsub("#.*","",textfile)
head(textfile)
textfile[1:20]
textfile <- gsub("<.*>","",textfile)
# print(head(textfile))
# get filename
filename <- basename(file)
#print(filename) # for visual inspection
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# print(subcorpus) # for visual inspection
# get the three letter identification code + the running number
code <- substring(substring(filename, regexpr("_", filename) + 1), 1, 8)
textfile[1:20]
filename
subcorpus
code
file.list <- list.files(path = "~/Github/NaLaFi/data",
recursive = T, full.names = T)
head(file.list)
length(file.list)
#same for the teddi sample (downloaded from https://drive.switch.ch/index.php/s/MJv7xFkzqlzFn0y)
file.list.teddi <- list.files(path = "~/Data/TeDDi_dumps/Teddi_unifiedformat",
recursive = T, full.names = T)
head(file.list.teddi)
length(file.list.teddi)
# downsample the number of teddi files
file.list.teddi <- sample(file.list.teddi, 1000)
#concatenate the two lists
file.list.combined <- c(file.list, file.list.teddi)
length(file.list.combined)
file2=/home/chris/Github/NaLaFi/data/non-writing/animal/animal_bhg_0001.txt
file2="/home/chris/Github/NaLaFi/data/non-writing/animal/animal_bhg_0001.txt"
textfile <- scan(file2, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
textfile
textfile <- gsub("#.*","",textfile)
textfile
textfile <- gsub("<.*>","",textfile)
textfile <- scan(file2, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
typeof(textfile)
textfile[1]
textfile[1:3]
textfile <- scan(file2, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
textfile <- textfile[!grepl('#.*', textfile)]
textfile
textfile = c("#aksdalknca", "#.mask","sajksd#","adlksdölke # askjlaks")
textfile <- textfile[!grepl('#.*', textfile)]
textfile
textfile = c("#aksdalknca", "#.mask","sajksd#","adlksdölke # askjlaks")
grepl('#.*', textfile)
textfile = c("#aksdalknca", "#.mask","sajksd#","adlksdölke # askjlaks")
textfile <- textfile[!grepl('# .*', textfile)]
textfile
textfile = c("#aksdalknca", "#.mask","sajksd#","adlksdölke # askjlaks")
textfile <- textfile[!grepl('^#.*$', textfile)]
textfile
textfile <- scan(file2, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
textfile <- textfile[!grepl('^#.*$', textfile)]
textfile
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0)
textfile <- textfile[!grepl('^#.*$', textfile)]
head(textfile)
textfile <- gsub("<.*>","",textfile)
filename <- basename(file)
subcorpus <- sub("_.*", "", filename)
# print(subcorpus) # for visual inspection
# get the three letter identification code + the running number
code <- substring(substring(filename, regexpr("_", filename) + 1), 1, 8)
filename
subcorpus
file
grepl('Teddi', file
)
file
file2
?ggMarginal()
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(ggplot2)
library(ggrepel)
library(plyr)
library(ggExtra)
library(ggpubr)
?ggMarginal()
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(class)
library(gridExtra)
library(gmodels)
library(caret)
estimations10.df <- read.csv("~/Github/NaLaFi/results/estimation10chars.csv")
estimations100.df <- read.csv("~/Github/NaLaFi/results/estimation100chars.csv")
estimations1000.df <- read.csv("~/Github/NaLaFi/results/estimation1000chars.csv")
selected <- c("writing","non-writing")
estimations.df <- estimations.df[estimations.df$corpus %in% selected, ]
View(estimations10.df)
estimations.subset <- estimations.df[c("corpus", "subcorpus", "huni.chars", "hrate.chars", "ttr.chars", "rm.chars")]
View(estimations.df)
estimations.df <- read.csv("~/Github/NaLaFi/results/estimation10chars.csv")
View(estimations.df)
selected <- c("writing","non-writing")
estimations.df <- estimations.df[estimations.df$corpus %in% selected, ]
View(estimations.df)
estimations.subset <- estimations.df[c("corpus", "subcorpus", "huni.chars", "hrate.chars", "ttr.chars", "rm.chars")]
View(estimations.subset)
estimations.subset <- na.omit(estimations.subset)
estimations.scaled <- cbind(estimations.subset[1], scale(estimations.subset[2:ncol(estimations.subset)]))
View(estimations.subset)
estimations.scaled <- cbind(estimations.subset[1:2], scale(estimations.subset[3:ncol(estimations.subset)]))
View(estimations.scaled)
View(estimations.subset)
?sample()
datasample <- sample(2, nrow(estimations.scaled), replace = TRUE, prob = c(0.67, 0.33))
head(datasample)
View(estimations.scaled)
estimations.training <- estimations.scaled[datasample == 1, 3:ncol(estimations.scaled)]
estimations.test <- estimations.scaled[datasample == 2, 3:ncol(estimations.scaled)]
View(estimations.training)
View(estimations.scaled)
View(estimations.scaled)
training.labels <- estimations.scaled[datasample == 1, 1]
training.labels
test.labels <- estimations.scaled[datasample == 2, 1]
test.labels
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = 2)
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = 4)
test.labels <- data.frame(test.labels)
# combining predicted and known species classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
class.comparison
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
# get macro average of F1 score across classes
f1 <- cm[["byClass"]][ , "F1"]
test.labels <- data.frame(test.labels)
test.labels
class.comparison <- data.frame(estimations.knn, test.labels)
class.comparison
estimations.knn
names(class.comparison) <- c("predicted", "observed")
class.comparison
head(class.comparison)
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
cm
f1 <- cm[["byClass"]][ , "F1"]
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = 2)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
# get macro average of F1 score across classes
f1 <- cm[["byClass"]][ , "F1"]
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = 4)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
cm
View(cm)
f1.macro.avg <- sum(cm[["byClass"]][ , "F1"])/length(unique(class.comparison$observed))
# creating a dataframe from known (true) test labels
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
# get macro average of F1 score across classes
f1 <- cm[["byClass"]][ , "F1"]
cm[["byClass"]]
cm[["byClass"]]["F1"]
f1 <- cm[["byClass"]]["F1"]
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
# get macro average of F1 score across classes
f1 <- cm[["byClass"]]["F1"]
f1.macro.avg <- sum(cm[["byClass"]]["F1"])/length(unique(class.comparison$observed))
# get macro average of recall score across classes
recall <- cm[["byClass"]]["Recall"]
recall.macro.avg <- sum(cm[["byClass"]]["Recall"])/length(unique(class.comparison$observed))
# get macro average of precision score across classes
precision <- cm[["byClass"]]["Precision"]
precision.macro.avg <- sum(cm[["byClass"]]["Precision"])/length(unique(class.comparison$observed))
knn.results <- data.frame(precision, recall, f1)
macro.avgs <- c(precision.macro.avg, recall.macro.avg, f1.macro.avg)
knn.results <- rbind(knn.results, macro.avgs)
row.names(knn.results)[length(unique(class.comparison$observed)) + 1] <- "Macro avg."
knn.results
length(unique(class.comparison$observed))
length(unique(class.comparison$observed)) + 1
knn.results
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
#get confusion matrix
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
# get macro average of F1 score across classes
f1 <- cm[["byClass"]]["F1"]
f1.macro.avg <- sum(cm[["byClass"]]["F1"])/length(unique(class.comparison$observed))
# get macro average of recall score across classes
recall <- cm[["byClass"]]["Recall"]
recall.macro.avg <- sum(cm[["byClass"]]["Recall"])/length(unique(class.comparison$observed))
# get macro average of precision score across classes
precision <- cm[["byClass"]]["Precision"]
precision.macro.avg <- sum(cm[["byClass"]]["Precision"])/length(unique(class.comparison$observed))
precision
knn.results <- data.frame(precision, recall, f1)
knn.results
f1 <- cm[["byClass"]]["F1"]
f1
length(unique(class.comparison$observed))
sum(cm[["byClass"]]["F1"])
f1.macro.avg
ethnologue <- read_csv("Glottolog2.7_Ethno_noNAs.csv")
library(tidyverse)
library(viridis)
library(scales)
ethnologue <- read_csv("Glottolog2.7_Ethno_noNAs.csv")
estimations.knn
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
head(class.comparison)
cm <- confusionMatrix(class.comparison$predicted, reference = class.comparison$observed)
cm
View(cm)
?confusionMatrix()
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed,
positive = "writing")
cm
head(class.comparison)
head(class.comparison)
View(class.comparison)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed,
positive = "writing")
# get precision, recall, and f1
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
cm
knn.results <- data.frame(precision, recall, f1)
knn.results <- data.frame(precision, recall, f1)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed,
positive = "writing")
# get precision, recall, and f1 from the output list of confusionMatrix()
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
View(cm)
k.choice = 4
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = k.choice)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed,
positive = "writing")
# get precision, recall, and f1 from the output list of confusionMatrix()
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
knn.results <- data.frame(precision, recall, f1, k.choice)
knn.results
knn.results <- data.frame(k.choice, precision, recall, f1)
knn.results
k = 4
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = k)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed,
positive = "writing")
# get precision, recall, and f1 from the output list of confusionMatrix()
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
knn.results <- data.frame(k, precision, recall, f1)
knn.results
knn.results <- data.frame(k, precision, recall, f1)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
knn.results <- data.frame(k, precision, recall, f1, row.names = F)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
knn.results <- data.frame(k, precision, recall, f1, row.names = F)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
knn.results <- data.frame(k, precision, recall, f1, row.names = "")
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
?data.frame()
knn.results <- data.frame(k, precision, recall, f1, row.names = NULL)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
?confusionMatrix()
15/(15+9)
26/(26+290)
15/(15+26)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed)
print(cm)
View(cm)
estimations.df <- read.csv("~/Github/NaLaFi/results/estimation10chars.csv")
estimations.subset <- estimations.df[c("corpus", "subcorpus", "huni.chars", "hrate.chars", "ttr.chars", "rm.chars")]
estimations.subset <- na.omit(estimations.subset)
estimations.scaled <- cbind(estimations.subset[1:2], scale(estimations.subset[3:ncol(estimations.subset)]))
set.seed(1234)
# Randomly generating our training and test samples with a respective ratio of 2/3 and 1/3
datasample <- sample(2, nrow(estimations.scaled), replace = TRUE, prob = c(0.67, 0.33))
# Generate training set
estimations.training <- estimations.scaled[datasample == 1, 3:ncol(estimations.scaled)]
# Generate test set
estimations.test <- estimations.scaled[datasample == 2, 3:ncol(estimations.scaled)]
training.labels <- estimations.scaled[datasample == 1, 1]
# Generate test labels
test.labels <- estimations.scaled[datasample == 2, 1]
k = 4
estimations.knn <- knn(train = estimations.training, test = estimations.test, cl = training.labels, k = k)
test.labels <- data.frame(test.labels)
# combining predicted and known classes
class.comparison <- data.frame(estimations.knn, test.labels)
# giving appropriate column names
names(class.comparison) <- c("predicted", "observed")
# inspecting our results table
head(class.comparison)
# get confusion matrix
cm <- confusionMatrix(class.comparison$predicted,
reference = class.comparison$observed)
print(cm)
f1 <- cm[["byClass"]]["F1"]
recall <- cm[["byClass"]]["Recall"]
precision <- cm[["byClass"]]["Precision"]
knn.results <- data.frame(k, precision, recall, f1, row.names = NULL)
knn.results.rounded <- round(knn.results, 2)
print(knn.results.rounded)
View(cm)
